{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Vectors\n",
    "\n",
    "Joint work of Harald Baayen en Martijn Naaijer and Dirk Roorda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.12\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys,os, re\n",
    "import collections\n",
    "from IPython.display import HTML, display_pretty, display_html\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = 'etcbc'\n",
    "version = '4b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s USING annox DATA COMPILED AT: 2016-01-27T19-01-17\n",
      "  1.84s INFO: LOADING PREPARED data: please wait ... \n",
      "  1.85s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  3.13s INFO: LOADED PREPARED data\n",
      "  3.13s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK semantic AT 2016-02-23T06-58-31\n"
     ]
    }
   ],
   "source": [
    "API = fabric.load(source+version, 'lexicon', 'semantic', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype\n",
    "        language lex phono gloss\n",
    "        sp\n",
    "        book chapter verse number\n",
    "        freq_lex\n",
    "    ''',''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='NORMAL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genre_specs = dict(\n",
    "    prose={\n",
    "        'Genesis', 'Exodus', 'Leviticus', 'Numeri', 'Deuteronomium', \n",
    "        'Josua', 'Judices', 'Samuel_I', 'Samuel_II', 'Reges_I', 'Reges_II', \n",
    "        'Jona', 'Ruth',   'Esther', 'Daniel', 'Esra', 'Nehemia', 'Chronica_I', 'Chronica_II',\n",
    "    },\n",
    "    prophecy={\n",
    "        'Jesaia', 'Jeremia', 'Ezechiel', 'Hosea', 'Joel', \n",
    "        'Obadia', 'Micha', 'Zephania', 'Haggai', 'Sacharia', 'Maleachi', \n",
    "        'Amos', 'Nahum', 'Habakuk',\n",
    "    },\n",
    "    poetry={\n",
    "        'Canticum','Proverbia','Ecclesiastes', 'Threni', 'Psalmi', 'Iob',\n",
    "    },\n",
    ")\n",
    "\n",
    "genre_books = collections.defaultdict(set)\n",
    "genre_sent = {}\n",
    "\n",
    "for b in F.otype.s('book'):\n",
    "    book_name = F.book.v(b)\n",
    "    for g in genre_specs:\n",
    "        if book_name in genre_specs[g]:\n",
    "            genre_books[g].add(b)\n",
    "            for s in L.d('sentence', b):\n",
    "                genre_sent[s] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 40s List of adjectives\n",
      " 1m 42s Done 606 adjectives\n"
     ]
    }
   ],
   "source": [
    "msg('List of adjectives')\n",
    "adjvs = set()\n",
    "for w in F.otype.s('word'):\n",
    "    if F.sp.v(w) == 'adjv':\n",
    "        adjvs.add((F.lex.v(w), F.gloss.v(w)))\n",
    "av = open('adjvs.txt', 'w')\n",
    "for a in sorted(adjvs): av.write('{}\\t{}\\n'.format(*a))\n",
    "av.close()\n",
    "msg('Done {} adjectives'.format(len(adjvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emo_adj_lines = '''\n",
    "<YJB/\tsad\n",
    "<Z===/\tstrong\n",
    "<ZWZ=/\tpowerful\n",
    ">BJR/\tstrong\n",
    ">BJR=/\tstrong\n",
    ">BL===/\tmourning\n",
    ">CM=/\tguilty\n",
    ">DJR/\tmighty\n",
    ">GM=/\tgrieved\n",
    ">JM/\tfrightful\n",
    ">JMTNJ/\tterrible\n",
    ">KZR/\tcruel\n",
    ">KZRJ/\tcruel\n",
    ">MJY/\tstrong\n",
    ">PJQ=/\tstrong\n",
    ">WJL/\tfoolish\n",
    ">WLJ/\tawkward\n",
    "BLH/\tworn out\n",
    "C<RWR/\thorrible\n",
    "C<RWRJ/\thorrible\n",
    "C>NN/\tat ease\n",
    "CLH/\tcarefree\n",
    "CLJV/\tmighty\n",
    "DK/\toppressed\n",
    "DWH/\tunwell\n",
    "DWJ=/\till\n",
    "FGJ>/\texalted\n",
    "FMX/\tjoyful\n",
    "G>/\thaughty\n",
    "G>H/\thaughty\n",
    "J<P/\tweary\n",
    "JG</\tweary\n",
    "JGJ<=/\tweary\n",
    "JGWR/\tfearing\n",
    "JHJR/\thaughty\n",
    "JR>/\tafraid\n",
    "KSJL/\tinsolent\n",
    "MGN=/\tinsolent\n",
    "MR/\tbitter\n",
    "MRD=/\trebellious\n",
    "MRJRJ/\tbitter\n",
    "MRR/\tbitter\n",
    "MZH/\thungry\n",
    "N<JM/\tpleasant\n",
    "N>WH/\tlovely\n",
    "NBL/\tstupid\n",
    "NDJB/\twilling\n",
    "NQJ/\tinnocent\n",
    "PSX=/\tlame\n",
    "PTLTL/\tqueer\n",
    "QCB=/\tattentive\n",
    "QCB==/\tattentive\n",
    "QN>/\tjealous\n",
    "QNW>/\tjealous\n",
    "R<B=/\thungry\n",
    "RC</\tguilty\n",
    "RGZ=/\texcited\n",
    "RXMNJ/\tcompassionate\n",
    "RXWM/\tcompassionate\n",
    "S<P/\tdespicable\n",
    "SKL/\tfoolish\n",
    "SLX/\tforgiving\n",
    "SMR/\tbristly\n",
    "SR/\tsullen\n",
    "SRB/\tobstinate\n",
    "TQJP/\tmighty\n",
    "TQJP/\tstrong\n",
    "WZR/\tguilty\n",
    "XNP/\talienated\n",
    "XNWN/\tgracious\n",
    "XPY=/\tdelighting\n",
    "XRD/\ttrembling\n",
    "XSJD/\tloyal\n",
    "XSN/\tstrong\n",
    "XT=/\tterror-filled\n",
    "XZQ/\tstrong\n",
    "XZQ==/\tstrong\n",
    "YM>/\tthirsty\n",
    "YNW</\thumble\n",
    "Z<P=/\traging\n",
    "ZD/\tinsolent\n",
    "'''.strip().split('\\n')\n",
    "emo_adj = {x.split('\\t')[0] for x in emo_adj_lines }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(emo_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    16s Counting hapaxes\n",
      "    18s 3076 hapaxes\n"
     ]
    }
   ],
   "source": [
    "msg('Counting hapaxes')\n",
    "hapax = set()\n",
    "for w in F.otype.s('word'):\n",
    "    if F.freq_lex.v(w) == '1': hapax.add(w)\n",
    "msg('{} hapaxes'.format(len(hapax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 07s Reading sentences\n",
      " 1m 10s Done. 374421 rows; 5889 lexemes (non-hapax)\n"
     ]
    }
   ],
   "source": [
    "msg('Reading sentences')\n",
    "rows = []\n",
    "vocabulaire = set()\n",
    "for (i, s) in enumerate(F.otype.s('sentence')):\n",
    "    lexemes = set()\n",
    "    wnodes = set()\n",
    "    for w in L.d('word', s):\n",
    "        lex = F.lex.v(w).replace('_', '~')\n",
    "        if lex not in lexemes:\n",
    "            if w not in hapax:\n",
    "                lexemes.add(lex)\n",
    "                wnodes.add(w)\n",
    "    vocabulaire |= lexemes\n",
    "    for w in sorted(wnodes):\n",
    "        rows.append((i, s, w, wnodes - {w}))\n",
    "msg('Done. {} rows; {} lexemes (non-hapax)'.format(len(rows), len(vocabulaire)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 4m 09s Producing cues\n",
      " 4m 14s Done: 374421 rows, 314333 different cues\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poetry  : 49764 rows\n",
      "prophecy: 86871 rows\n",
      "prose   : 237786 rows\n"
     ]
    }
   ],
   "source": [
    "msg('Producing cues')\n",
    "rowfile = {}\n",
    "gcount = collections.Counter()\n",
    "\n",
    "for g in genre_specs:\n",
    "    rowfile[g] = open('rows_{}.txt'.format(g), 'w')\n",
    "    rowfile[g].write('i\\tword\\tgloss\\tcues\\tfreq\\n')\n",
    "all_cues = set()\n",
    "\n",
    "for (i, s, w, cues) in rows:\n",
    "    cues_neat = '_'.join(sorted(F.lex.v(w).replace('_', '~') for w in cues))\n",
    "    all_cues.add(cues_neat)\n",
    "    g = genre_sent[s]\n",
    "    rowfile[g].write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(i+1, F.lex.v(w).replace('_', '~'), F.gloss.v(w), cues_neat, 1))\n",
    "    gcount[g] += 1\n",
    "\n",
    "for g in genre_specs:\n",
    "    rowfile[g].close()\n",
    "msg('Done: {} rows, {} different cues'.format(len(rows), len(all_cues)))\n",
    "for g in gcount:\n",
    "    print('{:<8}: {:>5} rows'.format(g, gcount[g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
