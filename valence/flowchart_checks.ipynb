{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://emdros.org\" target=\"_blank\"><img align=\"left\" src=\"files/images/Emdros-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowchart for verbs: checks \n",
    "\n",
    "We carry out checks for the benefit of running verbal valence flow charts.\n",
    "See the [flowchart](http://nbviewer.ipython.org/github/etcbc/laf-fabric-nbs/blob/master/valence/flowchart.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.3\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: http://shebanq-doc.readthedocs.org/en/latest/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import collections\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.10s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.10s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.75s INFO: USING DATA COMPILED AT: 2015-05-04T14-07-34\n",
      "  0.76s DETAIL: load main: G.node_anchor_min\n",
      "  0.82s DETAIL: load main: G.node_anchor_max\n",
      "  0.87s DETAIL: load main: G.node_sort\n",
      "  0.93s DETAIL: load main: G.node_sort_inv\n",
      "  1.36s DETAIL: load main: G.edges_from\n",
      "  1.43s DETAIL: load main: G.edges_to\n",
      "  1.50s DETAIL: load main: F.etcbc4_db_monads [node] \n",
      "  2.28s DETAIL: load main: F.etcbc4_db_oid [node] \n",
      "  3.24s DETAIL: load main: F.etcbc4_db_otype [node] \n",
      "  4.05s DETAIL: load main: F.etcbc4_ft_det [node] \n",
      "  4.31s DETAIL: load main: F.etcbc4_ft_function [node] \n",
      "  4.46s DETAIL: load main: F.etcbc4_ft_g_word_utf8 [node] \n",
      "  4.83s DETAIL: load main: F.etcbc4_ft_lex [node] \n",
      "  5.07s DETAIL: load main: F.etcbc4_ft_ls [node] \n",
      "  5.30s DETAIL: load main: F.etcbc4_ft_number [node] \n",
      "  5.90s DETAIL: load main: F.etcbc4_ft_prs [node] \n",
      "  6.16s DETAIL: load main: F.etcbc4_ft_rela [node] \n",
      "  6.79s DETAIL: load main: F.etcbc4_ft_sp [node] \n",
      "  7.01s DETAIL: load main: F.etcbc4_ft_trailer_utf8 [node] \n",
      "  7.17s DETAIL: load main: F.etcbc4_ft_vs [node] \n",
      "  7.42s DETAIL: load main: F.etcbc4_ft_vt [node] \n",
      "  7.67s DETAIL: load main: F.etcbc4_lex_gloss [node] \n",
      "  7.67s DETAIL: load main: F.etcbc4_lex_nametype [node] \n",
      "  7.67s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  7.69s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  7.71s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  7.75s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  7.76s DETAIL: load main: F.etcbc4_ft_mother [e] \n",
      "  7.83s DETAIL: load main: C.etcbc4_ft_mother -> \n",
      "  8.07s DETAIL: load main: C.etcbc4_ft_mother <- \n",
      "  8.25s DETAIL: load annox: F.etcbc4_db_monads [node] \n",
      "  8.25s DETAIL: load annox: F.etcbc4_db_oid [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_db_otype [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_det [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_function [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_g_word_utf8 [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_lex [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_ls [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_number [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_prs [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_rela [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_sp [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_trailer_utf8 [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_vs [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_ft_vt [node] \n",
      "  8.26s DETAIL: load annox: F.etcbc4_lex_gloss [node] \n",
      "  8.71s DETAIL: load annox: F.etcbc4_lex_nametype [node] \n",
      "  8.92s DETAIL: load annox: F.etcbc4_sft_book [node] \n",
      "  8.92s DETAIL: load annox: F.etcbc4_sft_chapter [node] \n",
      "  8.93s DETAIL: load annox: F.etcbc4_sft_label [node] \n",
      "  8.93s DETAIL: load annox: F.etcbc4_sft_verse [node] \n",
      "  8.93s DETAIL: load annox: F.etcbc4_ft_mother [e] \n",
      "  8.93s DETAIL: load annox: C.etcbc4_ft_mother -> \n",
      "  8.93s DETAIL: load annox: C.etcbc4_ft_mother <- \n",
      "  8.93s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/valence/__log__valence.txt\n",
      "  8.93s DETAIL: prep prep: G.node_sort\n",
      "  9.03s DETAIL: prep prep: G.node_sort_inv\n",
      "    10s DETAIL: prep prep: L.node_up\n",
      "    15s DETAIL: prep prep: L.node_down\n",
      "    25s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-05-04T14-07-34\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.02s DETAIL: keep main: F.etcbc4_ft_number [node] \n",
      "  0.02s DETAIL: keep main: F.etcbc4_sft_book [node] \n",
      "  0.02s DETAIL: keep main: F.etcbc4_sft_chapter [node] \n",
      "  0.02s DETAIL: keep main: F.etcbc4_sft_verse [node] \n",
      "  0.02s DETAIL: keep annox: F.etcbc4_db_otype [node] \n",
      "  0.02s DETAIL: keep annox: F.etcbc4_ft_number [node] \n",
      "  0.02s DETAIL: keep annox: F.etcbc4_sft_book [node] \n",
      "  0.02s DETAIL: keep annox: F.etcbc4_sft_chapter [node] \n",
      "  0.02s DETAIL: keep annox: F.etcbc4_sft_verse [node] \n",
      "  0.02s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK valence AT 2015-07-09T15-51-09\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK valence AT 2015-07-09T15-51-09\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "API = fabric.load('etcbc{}'.format(version), 'lexicon', 'valence', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        oid otype monads\n",
    "        function rela\n",
    "        g_word_utf8 trailer_utf8\n",
    "        lex prs sp ls vs vt nametype det gloss\n",
    "        book chapter verse label number\n",
    "    ''',\n",
    "    '''\n",
    "        mother\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Here we specify details of the flow chart process such as which lexemes to look for, which senses they have, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicates = {'Pred', 'PreS', 'PreO', 'PtcO', 'PreC'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the target clauses\n",
    "\n",
    "The target clauses are those clauses that contain the verb NTN in the Qal in a phrase with function ``Pred`` and friends.\n",
    "But first we do some checks:\n",
    "\n",
    "* how many verbs clauses can have in predicates\n",
    "* examine in what phrases and tenses the selected verbs occurs in the Qal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 02s Examining verbs in predicates in clauses\n",
      " 1m 05s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69424 clauses have a predicate with a verb\n",
      "69424 clause_atoms have a predicate with a verb\n",
      "330 clauses have multiple verb occurrences of which 1 are still single lexeme\n",
      "330 clause_atoms have multiple verb occurrences of which 1 are still single lexeme\n"
     ]
    }
   ],
   "source": [
    "msg('Examining verbs in predicates in clauses')\n",
    "verb_dist_clause = collections.defaultdict(lambda: [])\n",
    "verb_dist_clause_atom = collections.defaultdict(lambda: [])\n",
    "for p in F.otype.s('phrase'):\n",
    "    pf = F.function.v(p)\n",
    "    if pf not in predicates: continue\n",
    "    c = L.u('clause', p)\n",
    "    ca = L.u('clause_atom', p)\n",
    "    for w in L.d('word', p):\n",
    "        if F.sp.v(w) != 'verb': continue\n",
    "        verb_dist_clause[c].append(F.lex.v(w))\n",
    "        verb_dist_clause_atom[ca].append(F.lex.v(w))\n",
    "msg('Done')\n",
    "nverbc = len(verb_dist_clause)\n",
    "nverbca = len(verb_dist_clause_atom)\n",
    "\n",
    "print('{} clauses have a predicate with a verb'.format(nverbc))\n",
    "print('{} clause_atoms have a predicate with a verb'.format(nverbca))\n",
    "\n",
    "multiples_c = 0\n",
    "onelex_c = 0\n",
    "for c in verb_dist_clause:\n",
    "    lexes = verb_dist_clause[c]\n",
    "    if len(lexes) == 1: continue\n",
    "    multiples_c += 1\n",
    "    if len(set(lexes)) == 1: onelex_c += 1\n",
    "print('{} clauses have multiple verb occurrences of which {} are still single lexeme'.format(\n",
    "        multiples_c, onelex_c,\n",
    "))\n",
    "multiples_ca = 0\n",
    "onelex_ca = 0\n",
    "for ca in verb_dist_clause_atom:\n",
    "    lexes = verb_dist_clause_atom[ca]\n",
    "    if len(lexes) == 1: continue\n",
    "    multiples_ca += 1\n",
    "    if len(set(lexes)) == 1: onelex_ca += 1\n",
    "print('{} clause_atoms have multiple verb occurrences of which {} are still single lexeme'.format(\n",
    "        multiples_ca, onelex_ca,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stick to clauses, we gain nothing by considering clause_atoms instead.\n",
    "\n",
    "We need to look more precisely in what happens in clauses with multiple verbs in a predicate.\n",
    "Are there multiples predicates in those clauses, or are there multiple verbs in the single predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 40s Examining verbs in predicates in clauses (revisited)\n",
      " 1m 42s Done\n",
      " 1m 42s \n",
      "69094 single verb clauses\n",
      "  281 known multiple cases\n",
      "   49 unknown multiple verb clauses\n",
      "69424 clauses in total\n"
     ]
    }
   ],
   "source": [
    "msg('Examining verbs in predicates in clauses (revisited)')\n",
    "\n",
    "def known_case(vs):\n",
    "    be = {'HJH[', 'HWH['}\n",
    "    if len(vs) != 2: return False\n",
    "    ps = collections.defaultdict(lambda: set())\n",
    "    for (p,w) in vs: ps[F.function.v(p)].add(F.lex.v(w))\n",
    "    if len(ps['Pred'] | ps['PreS']) == 1 and len(be & (ps['Pred'] | ps['PreS'])) != 0: return True\n",
    "    return False\n",
    "\n",
    "verb_dist = collections.defaultdict(lambda: [])\n",
    "for p in F.otype.s('phrase'):\n",
    "    pf = F.function.v(p)\n",
    "    if pf not in predicates: continue\n",
    "    c = L.u('clause', p)\n",
    "    for w in L.d('word', p):\n",
    "        if F.sp.v(w) != 'verb': continue\n",
    "        verb_dist[c].append((p, w))\n",
    "msg('Done')\n",
    "\n",
    "of = outfile('verb_dist.txt')\n",
    "multiple = 0\n",
    "good = 0\n",
    "for c in verb_dist:\n",
    "    vs = verb_dist[c]\n",
    "    if len(vs) == 1: continue\n",
    "    multiple += 1\n",
    "    if known_case(vs):\n",
    "        good += 1\n",
    "        continue\n",
    "    of.write('\\n{} {}:{}#{}_{}\\n'.format(\n",
    "        F.book.v(L.u('book', c)),\n",
    "        F.chapter.v(L.u('chapter', c)),\n",
    "        F.verse.v(L.u('verse', c)),\n",
    "        F.number.v(L.u('sentence', c)),\n",
    "        F.number.v(c),\n",
    "    ))\n",
    "    for (p,w) in vs:\n",
    "        of.write('\\t{} {} has {}\\n'.format(p, F.function.v(p), F.lex.v(w)))\n",
    "of.close()\n",
    "\n",
    "msg('''\n",
    "{:>5} single verb clauses\n",
    "{:>5} known multiple cases\n",
    "{:>5} unknown multiple verb clauses\n",
    "{:>5} clauses in total'''.format(\n",
    "    len(verb_dist) - multiple,\n",
    "    good,\n",
    "    multiple - good,\n",
    "    len(verb_dist),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2m 51s Examining the occurrences of BR>[, FJM[, NTN[\n",
      " 2m 54s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred perf   831 x\n",
      "Pred impf   471 x\n",
      "Pred wayq   423 x\n",
      "Pred infc   159 x\n",
      "PreO perf   158 x\n",
      "PreC ptca   131 x\n",
      "Pred impv   130 x\n",
      "PreO wayq    85 x\n",
      "PreO impf    65 x\n",
      "PreS infc    25 x\n",
      "PreC ptcp    15 x\n",
      "PreO infc    14 x\n",
      "Modi infa     8 x\n",
      "Pred infa     8 x\n",
      "PreO impv     6 x\n",
      "PtcO ptca     4 x\n",
      "Cmpl ptca     1 x\n",
      "Objc ptca     1 x\n",
      "Objc ptcp     1 x\n",
      "Subj ptca     1 x\n",
      "Total      2537 x\n",
      "BR>[\n",
      "     Pred perf    13 x\n",
      "     PreC ptca    11 x\n",
      "     PreO perf     7 x\n",
      "     Pred wayq     2 x\n",
      "     Objc ptca     1 x\n",
      "     Pred impf     1 x\n",
      "     Pred impv     1 x\n",
      "     Pred infc     1 x\n",
      "     Subj ptca     1 x\n",
      "     Total        38 x\n",
      "FJM[\n",
      "     Pred perf   146 x\n",
      "     Pred wayq   139 x\n",
      "     Pred impf   104 x\n",
      "     Pred impv    54 x\n",
      "     PreO perf    39 x\n",
      "     Pred infc    31 x\n",
      "     PreO impf    21 x\n",
      "     PreC ptca    15 x\n",
      "     PreO wayq    14 x\n",
      "     PreS infc     5 x\n",
      "     PreC ptcp     4 x\n",
      "     Modi infa     2 x\n",
      "     PreO impv     2 x\n",
      "     PreO infc     2 x\n",
      "     Pred infa     1 x\n",
      "     Total       579 x\n",
      "NTN[\n",
      "     Pred perf   672 x\n",
      "     Pred impf   366 x\n",
      "     Pred wayq   282 x\n",
      "     Pred infc   127 x\n",
      "     PreO perf   112 x\n",
      "     PreC ptca   105 x\n",
      "     Pred impv    75 x\n",
      "     PreO wayq    71 x\n",
      "     PreO impf    44 x\n",
      "     PreS infc    20 x\n",
      "     PreO infc    12 x\n",
      "     PreC ptcp    11 x\n",
      "     Pred infa     7 x\n",
      "     Modi infa     6 x\n",
      "     PreO impv     4 x\n",
      "     PtcO ptca     4 x\n",
      "     Cmpl ptca     1 x\n",
      "     Objc ptcp     1 x\n",
      "     Total      1920 x\n"
     ]
    }
   ],
   "source": [
    "target_lexemes = {'NTN[', 'FJM[', 'BR>['}\n",
    "msg('Examining the occurrences of {}'.format(', '.join(sorted(target_lexemes))))\n",
    "qal_dist_all = collections.Counter()\n",
    "qal_dist = collections.defaultdict(lambda: collections.Counter())\n",
    "for w in F.otype.s('word'):\n",
    "    lex = F.lex.v(w)\n",
    "    if lex in target_lexemes and F.vs.v(w) == 'qal':\n",
    "        wt = F.vt.v(w)\n",
    "        wf = F.function.v(L.u('phrase', w))\n",
    "        qal_dist_all[(wf,wt)] += 1\n",
    "        qal_dist[lex][(wf,wt)] += 1\n",
    "msg('Done')\n",
    "tot = 0\n",
    "for (label, n) in sorted(qal_dist_all.items(), key=lambda y: (-y[1], y[0])):\n",
    "    tot += n\n",
    "    print('{:<4} {:<4} {:>5} x'.format(label[0], label[1], n))\n",
    "print('Total     {:>5} x'.format(tot))\n",
    "for lx in sorted(qal_dist):\n",
    "    print(lx)\n",
    "    tot = 0\n",
    "    for (label, n) in sorted(qal_dist[lx].items(), key=lambda y: (-y[1], y[0])):\n",
    "        tot += n\n",
    "        print('     {:<4} {:<4} {:>5} x'.format(label[0], label[1], n))\n",
    "    print('     Total     {:>5} x'.format(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision: we restrict to cases where the verb occurs as *predicate*, i.e. in a phrase with function as mentioned in the parameter ``predicates`` defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the object phrases\n",
    "\n",
    "It is important to know whether a direct object has >T or not.\n",
    "If it has >T, it is usually at the beginning, although some adverbial words might precede it.\n",
    "So, what can we expect?\n",
    "Here we explore everything that may precede the first >T in a phrase with function ``Objc``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3m 27s Exploring >T prefixes\n",
      " 3m 30s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W                   :  1826 x\n",
      "H                   :  1371 x\n",
      "KL/                 :   535 x\n",
      "BN/                 :   288 x\n",
      "DBR/                :   258 x\n",
      "MH                  :   223 x\n",
      "BJT/                :   213 x\n",
      "JD/                 :   212 x\n",
      ">JC/                :   207 x\n",
      "PNH/                :   198 x\n"
     ]
    }
   ],
   "source": [
    "msg('Exploring >T prefixes')\n",
    "etprefixes = collections.Counter()\n",
    "etprefix_words = collections.Counter()\n",
    "for p in F.otype.s('phrase'):\n",
    "    if F.function.v(p) != 'Objc': continue\n",
    "    prefix = []\n",
    "    for w in L.d('word', p):\n",
    "        if F.lex.v(w) == '>T':\n",
    "            found = True\n",
    "            break\n",
    "        prefix.append(w)\n",
    "    if found:\n",
    "        prefstr = '-'.join(F.sp.v(w) for w in prefix)\n",
    "        etprefixes[prefstr] += 1\n",
    "        for w in prefix:\n",
    "            etprefix_words[F.lex.v(w)]+= 1 \n",
    "msg('Done')\n",
    "for x in sorted(etprefix_words.items(), key=lambda y: (-y[1], y[0]))[0:10]:\n",
    "    print('{:<20}: {:>5} x'.format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are many cases where material in a direct object phrase precedes the object marker.\n",
    "Explore them with\n",
    "[Dirk Roorda: Material before אֶת](https://shebanq.ancient-data.org/hebrew/query?version=4b&id=878).\n",
    "For the moment we use a simple criterion: an direct object is an marked object if the object marker occurs *somewhere* in the phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the object clauses\n",
    "\n",
    "We want to know more about object clauses.\n",
    "Do they have a mother, and if yes, how many, of which type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3m 38s Exploring the mothers of Objc-clauses\n",
      " 3m 40s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427 object clauses of total 87900\n",
      "clause Adju     :   92x\n",
      "clause Attr     :   25x\n",
      "clause Cmpl     :    5x\n",
      "clause CoVo     :   17x\n",
      "clause Coor     :   30x\n",
      "clause NA       : 1234x\n",
      "clause Objc     :   11x\n",
      "clause PreC     :    2x\n",
      "clause Resu     :    9x\n",
      "clause Subj     :    2x\n",
      "Total 1427 mothers\n",
      "# mothers =  1 for 1427 object clauses\n",
      "Total 1427 object clauses with a mother\n"
     ]
    }
   ],
   "source": [
    "msg('Exploring the mothers of Objc-clauses')\n",
    "noc = 0\n",
    "nc = 0\n",
    "mothers = collections.Counter()\n",
    "has_mothers = collections.Counter()\n",
    "for c in F.otype.s('clause'):\n",
    "    nc += 1\n",
    "    if F.rela.v(c) == 'Objc':\n",
    "        noc += 1\n",
    "        nmothers = 0\n",
    "        for x in C.mother.v(c):\n",
    "            nmothers += 1\n",
    "            motype = F.otype.v(x)\n",
    "            mytype = motype\n",
    "            if motype == 'phrase':\n",
    "                mytype = 'phrase {}'.format(F.function.v(x))\n",
    "            elif motype == 'clause':\n",
    "                mytype = 'clause {}'.format(F.rela.v(x))\n",
    "            mothers[mytype] += 1\n",
    "        has_mothers[nmothers] += 1\n",
    "msg('Done')\n",
    "print('{} object clauses of total {}'.format(noc, nc))\n",
    "totaln = 0\n",
    "for otp in sorted(mothers):\n",
    "    thisn = mothers[otp]\n",
    "    totaln += thisn\n",
    "    print('{:<16}: {:>4}x'.format(otp, thisn))\n",
    "print('Total {} mothers'.format(totaln))\n",
    "totaln = 0\n",
    "for x in sorted(has_mothers, reverse=True):\n",
    "    thisn = has_mothers[x]\n",
    "    if x != 0: totaln += thisn\n",
    "    print('# mothers = {:>2} for {:>4} object clauses'.format(x, thisn))\n",
    "print('Total {} object clauses with a mother'.format(totaln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, every object clause has exactly one mother, and it is always a clause.\n",
    "I presume that the object clause acts as a direct object of the verb in the mother clause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement promotion\n",
    "\n",
    "We want to promote some complements to (secundary) direct objects, in cases as\n",
    "\n",
    "*I make you into **a great people** *.\n",
    "\n",
    "The question is, can we do this rule-based, or do we have to manually add this information to the data we are working with?\n",
    "\n",
    "Let us generate a list of all cases.\n",
    "\n",
    "We are looking for a clause and a phrase in it with function ``Cmpl``.\n",
    "The phrase should start with one of the lexemes ``K``, ``L``, not carrying a pronominal suffix.\n",
    "\n",
    "There should be an other object in the sentence, but the object could be implied.\n",
    "So, for the moment we do not make a restriction of it, but we highlight the presence of objects, relatives, and phrases starting with the lexeme ``MN``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1h 07m 49s Investigating promotion\n",
      " 1h 07m 52s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clauses                           :  87900\n",
      "with any candidates                     :   5141\n",
      "with  3 candidates                      :      1\n",
      "with  2 candidates                      :     41\n",
      "with  1 candidates                      :   5099\n",
      "with any objects                        :   1780\n",
      "with  2 objects                         :     61\n",
      "with  1 objects                         :   1719\n"
     ]
    }
   ],
   "source": [
    "msg('Investigating promotion')\n",
    "predicates = {'Pred', 'PreS', 'PreO', 'PtcO', 'PreC'}\n",
    "objectsf = {'Objc', 'PreO', 'PtcO'}\n",
    "no_prs = {'absent', 'n/a'}\n",
    "prom_preps = {'K', 'L'}\n",
    "\n",
    "of = outfile('promotion.csv')\n",
    "fields = '''book chapter verse sentence clause verbs #objs #cands'''.strip().split()\n",
    "of_fmt = '{}'+('\\t{}' * (len(fields)-1))+'\\n'\n",
    "of.write(of_fmt.format(*fields))\n",
    "\n",
    "ncands = collections.Counter()\n",
    "nobjs = collections.Counter()\n",
    "nclauses = 0\n",
    "\n",
    "for c in F.otype.s('clause'):\n",
    "    nclauses += 1\n",
    "    verbs = []\n",
    "    cws = L.d('word', c)\n",
    "    cw1 = cws[0]\n",
    "    for w in cws:\n",
    "        if F.sp.v(w) == 'verb':\n",
    "            verbs.append(F.lex.v(w))\n",
    "    cands = []\n",
    "    ps = L.d('phrase', c)\n",
    "    for p in ps:\n",
    "        if F.function.v(p) != 'Cmpl': continue\n",
    "        ws = L.d('word', p)\n",
    "        w_one = ws[0]\n",
    "        w_lex = F.lex.v(w_one)\n",
    "        w_prs = F.prs.v(w_one)\n",
    "        if w_prs not in no_prs: continue\n",
    "        if w_lex not in prom_preps: continue\n",
    "        cands.append(p)\n",
    "    nc = len(cands)\n",
    "    if nc == 0: continue\n",
    "\n",
    "    ncands[nc] += 1\n",
    "\n",
    "    objects = []\n",
    "    for p in ps:\n",
    "        if F.function.v(p) in objectsf:\n",
    "            objects.append(p)\n",
    "    no = len(objects)\n",
    "    if no != 0:\n",
    "        nobjs[no] += 1\n",
    "\n",
    "    of.write(of_fmt.format(\n",
    "        F.book.v(L.u('book', cw1)),\n",
    "        F.chapter.v(L.u('chapter', cw1)),\n",
    "        F.verse.v(L.u('verse', cw1)),\n",
    "        F.number.v(L.u('sentence', cw1)),\n",
    "        F.number.v(L.u('clause', cw1)),\n",
    "        ' '.join(verbs),\n",
    "        no,\n",
    "        nc,\n",
    "    ))\n",
    "of.close()\n",
    "msg('Done')\n",
    "print('{:<40}: {:>6}'.format('Total clauses', nclauses))\n",
    "print('{:<40}: {:>6}'.format('with any candidates', sum(ncands.values())))\n",
    "for nc in sorted(ncands, reverse=True):\n",
    "    print('{:<40}: {:>6}'.format('with {:>2} candidates'.format(nc), ncands[nc]))\n",
    "print('{:<40}: {:>6}'.format('with any objects', sum(nobjs.values())))\n",
    "for no in sorted(nobjs, reverse=True):\n",
    "    print('{:<40}: {:>6}'.format('with {:>2} objects'.format(no), nobjs[no]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implied objects\n",
    "\n",
    "# The relativum\n",
    "\n",
    "How many occurrences of >CR are there?\n",
    "\n",
    "What do we know about their antecedents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 5m 55s Investigating relative clauses\n",
      " 5m 56s The word >CR occurs 5500 times\n",
      " 5m 56s There are 5263 ashers with a mother; 0 have multiple mothers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3513 clauses have mother of type phrase\n",
      " 1173 clauses have mother of type clause\n",
      "  577 clauses have mother of type word\n"
     ]
    }
   ],
   "source": [
    "msg('Investigating relative clauses')\n",
    "ashers = list(F.lex.s('>CR'))\n",
    "msg('The word >CR occurs {} times'.format(len(ashers)))\n",
    "\n",
    "aclauses = collections.OrderedDict()\n",
    "multiples = collections.Counter()\n",
    "for a in ashers:\n",
    "    c = L.u('clause', a)\n",
    "    m = list(C.mother.v(c))\n",
    "    if m:\n",
    "        if c in aclauses:\n",
    "            multiples[c]  += 1\n",
    "        else:\n",
    "            aclauses[c] = m[0]\n",
    "\n",
    "msg('There are {} ashers with a mother; {} have multiple mothers'.format(len(aclauses), len(multiples)))         \n",
    "for (c, n) in sorted(multiples.items(), key=lambda y: -y[1]):\n",
    "    print('Clause {} has {} ashers'.format(c, n))\n",
    "\n",
    "mothertypes = collections.defaultdict(lambda: [])\n",
    "for c in aclauses:\n",
    "    mothertypes[F.otype.v(aclauses[c])].append(c)\n",
    "    \n",
    "for (mt, ms) in sorted(mothertypes.items(), key=lambda y: -len(y[1])):\n",
    "    print('{:>5} clauses have mother of type {}'.format(len(ms), mt))\n",
    "\n",
    "of = outfile('asher.txt')\n",
    "for mtype in mothertypes:\n",
    "    of.write('[{}]\\n'.format(mtype))\n",
    "    for c in mothertypes[mtype]:\n",
    "        m = aclauses[c]\n",
    "        pair = sorted([c, m], key=NK)\n",
    "        w = L.d('word', c)[0]\n",
    "        of.write('{:<20} {:>3}:{:>3}#{:>2}_{:>2} {:<6} {}\\n'.format(\n",
    "            F.book.v(L.u('book', w)),\n",
    "            F.chapter.v(L.u('chapter', w)),\n",
    "            F.verse.v(L.u('verse', w)),\n",
    "            F.number.v(L.u('sentence', w)),\n",
    "            F.number.v(c),\n",
    "            F.otype.v(m),\n",
    "            ''.join('C' if x == c else 'M' for x in pair),\n",
    "        ))\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional explorations\n",
    "\n",
    "Below we generate a list of nouns in order to spot the ones that refer to people.\n",
    "A list of the spotted nouns is used above in the algorithm to separate locative complements from indirect objects.\n",
    "\n",
    "We also need lists of lexemes that have something locative in them, or that refer to body parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cands = collections.defaultdict(lambda: collections.Counter())\n",
    "verbs = collections.Counter()\n",
    "glosses = {}\n",
    "for w in F.otype.s('word'):\n",
    "    ls = F.ls.v(w)\n",
    "    sp = F.sp.v(w)\n",
    "    if sp == 'subs':\n",
    "        cands[ls][F.lex.v(w)] += 1\n",
    "    elif sp == 'verb':\n",
    "        verbs[F.lex.v(w)] += 1\n",
    "    glosses[F.lex.v(w)] = F.gloss.v(w)\n",
    "\n",
    "of = outfile('words.txt')\n",
    "for ls in cands:\n",
    "    of.write('[{}]\\n'.format(ls))\n",
    "    for cand in sorted(cands[ls]):\n",
    "        of.write('{:<10} : {:>5} x {}\\n'.format(cand, cands[ls][cand], glosses[cand]))\n",
    "    of.write('\\n')\n",
    "of.close()\n",
    "of = outfile('verbs.txt')\n",
    "for vb in sorted(verbs):\n",
    "    of.write('{:<10} : {:>5} x {}\\n'.format(vb, verbs[vb], glosses[vb]))\n",
    "of.write('\\n')\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
