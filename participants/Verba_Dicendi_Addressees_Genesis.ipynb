{
 "metadata": {
  "name": "",
  "signature": "sha256:9b26d95b17bf3586b2cd7260947b36f76217b5a4aee8c75eeb48dda277047ff6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.lib import Transcription, monad_set\n",
      "from etcbc.trees import Tree\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.3.1\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API=fabric.load('bhs4', '--', 'participants_in_psalms', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype nu ps gn prs ls lex g_cons\n",
      "        function txt\n",
      "        book chapter label\n",
      "    ''',\n",
      "    '''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='DETAIL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-06-30T05-57-52\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.02s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.15s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.26s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.37s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.03s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.18s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.33s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.35s DETAIL: load main: F.shebanq_ft_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.52s DETAIL: load main: F.shebanq_ft_g_cons [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.80s DETAIL: load main: F.shebanq_ft_gn [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.02s DETAIL: load main: F.shebanq_ft_lex [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.31s DETAIL: load main: F.shebanq_ft_ls [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: load main: F.shebanq_ft_nu [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.52s DETAIL: load main: F.shebanq_ft_prs [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.20s DETAIL: load main: F.shebanq_ft_ps [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.61s DETAIL: load main: F.shebanq_ft_txt [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.75s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.84s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.90s DETAIL: load main: F.shebanq_sft_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.07s LOGFILE=C:\\Users\\Gino/laf-fabric-output/bhs4/participants_in_psalms/__log__participants_in_psalms.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.08s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.71s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s INFO: DATA LOADED FROM SOURCE bhs4 AND ANNOX -- FOR TASK participants_in_psalms AT 2014-09-11T11-47-22\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def analyze_book():\n",
      "    f = outfile('verba_dicendi_addressees_genesis.csv')\n",
      "    inBook = False\n",
      "    inSubject = False\n",
      "    inObject = False\n",
      "    inComplement = False\n",
      "    inVerbDicCl = False\n",
      "\n",
      "    marked_speech = False\n",
      "    verb_dic = False\n",
      "    quot_domains = [\"xxx\"]\n",
      "    new_domain = domain = \"\"\n",
      "    \n",
      "    subject = \"\"\n",
      "    obj = \"\"\n",
      "    complement = \"\"\n",
      "    text = \"\"\n",
      "    suffix = \"\"\n",
      "    ch = \"\"\n",
      "    vs = \"\"\n",
      "    volgnr = 0\n",
      "    \n",
      "    pnMark = \"\"\n",
      "    \n",
      "    marked_references = collections.defaultdict(dict)\n",
      "    unmarked_references = collections.defaultdict(dict)\n",
      "    verses = collections.defaultdict(list)\n",
      "    verse_tts = collections.defaultdict(list)\n",
      "    verbs = collections.defaultdict(dict)\n",
      "    vocatives = collections.defaultdict(dict)\n",
      "   \n",
      "    for node in NN():\n",
      "        otype = F.otype.v(node)\n",
      "        if otype == 'book':\n",
      "            if F.book.v(node) == \"Genesis\":\n",
      "                inBook = True\n",
      "            else:\n",
      "                inBook = False\n",
      "        elif inBook and otype == \"chapter\":\n",
      "            ch = F.chapter.v(node)\n",
      "            marked_references[ch] = collections.defaultdict(dict)\n",
      "            unmarked_references[ch] = collections.defaultdict(dict)\n",
      "            verbs[ch] = collections.defaultdict(dict)\n",
      "            vocatives[ch] = collections.defaultdict(dict)\n",
      "            quot_domains = [\"xxx\"]\n",
      "            marked_speech = False\n",
      "            verb_dic = False\n",
      "        elif inBook and otype == \"verse\":\n",
      "            vs = F.label.v(node)\n",
      "            marked_references[ch][vs] = collections.defaultdict(str)\n",
      "            unmarked_references[ch][vs] = collections.defaultdict(str)\n",
      "            verbs[ch][vs] = collections.defaultdict(dict)\n",
      "            vocatives[ch][vs] = collections.defaultdict(str)\n",
      "            verses[ch].append(vs)\n",
      "            domain = \"\"\n",
      "            volgnr = 0\n",
      "        elif inBook and otype == \"clause\":\n",
      "            if inVerbDicCl: \n",
      "                if subject != \"\":\n",
      "                    verbs[ch][vs][domain + str(volgnr)]['su'] = subject\n",
      "                elif obj != \"\":\n",
      "                    verbs[ch][vs][domain + str(volgnr)]['ob'] = obj\n",
      "                elif complement != \"\":\n",
      "                    verbs[ch][vs][domain + str(volgnr)]['co'] = complement\n",
      "            \n",
      "                verbs[ch][vs][domain + str(volgnr)]['txt'] = text\n",
      "            inVerbDicCl = False\n",
      "            new_domain = F.txt.v(node)\n",
      "            \n",
      "            if new_domain != domain:\n",
      "                volgnr += 1\n",
      "                marked_references[ch][vs][new_domain + str(volgnr)] = \"\"\n",
      "                unmarked_references[ch][vs][new_domain + str(volgnr)] = \"\"\n",
      "                verbs[ch][vs][new_domain + str(volgnr)] = collections.defaultdict(str)\n",
      "                vocatives[ch][vs][new_domain + str(volgnr)] = \"\"\n",
      "                verse_tts[vs].append(new_domain + str(volgnr))\n",
      "            domain = new_domain\n",
      "            \n",
      "            subject = \"\"\n",
      "            obj = \"\"\n",
      "            complement = \"\"\n",
      "            text = \"\"\n",
      "            \n",
      "            if (vocatives[ch][vs][domain + str(volgnr)] != \"\") and (vocatives[ch][vs][domain + str(volgnr)][-1:] != ','):\n",
      "                vocatives[ch][vs][domain + str(volgnr)] += \",\"\n",
      "        elif inBook and otype == \"phrase\":\n",
      "            inSubject = False\n",
      "            inObject = False\n",
      "            inComplement = False\n",
      "            inVocative = False\n",
      "\n",
      "            if F.function.v(node) == \"Subj\":\n",
      "                inSubject = True\n",
      "            elif F.function.v(node) == \"Voct\":\n",
      "                inVocative = True\n",
      "            elif F.function.v(node) == \"Objc\":\n",
      "                inObject = True\n",
      "            elif F.function.v(node) == \"Cmpl\":\n",
      "                inComplement = True\n",
      "        elif inBook and otype == \"word\":\n",
      "            text += F.g_cons.v(node) + \" \"\n",
      "            suffix = F.prs.v(node)\n",
      "            \n",
      "            pnMark = \"\"\n",
      "            \n",
      "            if F.ls.v(node) == \"quot\":\n",
      "                verb_dic = True\n",
      "                inVerbDicCl = True\n",
      "                quot_domains.append(domain + \"Q\")\n",
      "                verbs[ch][vs][domain + str(volgnr)]['vb'] = F.lex.v(node)\n",
      "            elif verb_dic and domain == quot_domains[-1]:    # Hier begint dan de ingebedde directe rede na een verbum dicendi\n",
      "                verb_dic = False\n",
      "                marked_speech = True\n",
      "            elif marked_speech and not verb_dic:\n",
      "                while len(quot_domains) > 1:\n",
      "                    if len(domain) < len(quot_domains[-1]):\n",
      "                        quot_domains.pop()\n",
      "                    elif len(domain) >= len(quot_domains[-1]):\n",
      "                        break\n",
      "                if len(quot_domains) == 1:\n",
      "                    marked_speech = False\n",
      "            \n",
      "            if inSubject:\n",
      "                subject += F.g_cons.v(node) + \" \"\n",
      "            elif inObject:\n",
      "                obj += F.g_cons.v(node) + \" \"\n",
      "            elif inComplement:\n",
      "                complement += F.g_cons.v(node) + \" \"\n",
      "            elif inVocative:\n",
      "                vocatives[ch][vs][domain + str(volgnr)] += F.g_cons.v(node) + \" \"\n",
      "            \n",
      "            if ((F.ps.v(node) == \"p1\" and F.nu.v(node) == \"sg\") or (suffix == \"NJ\" or suffix == \"J\")):\n",
      "                pnMark = '1s'\n",
      "            elif ((F.ps.v(node) == \"p1\" and F.nu.v(node) == \"pl\") or (suffix == \"NW\")):\n",
      "                pnMark = '1p'\n",
      "            elif ((F.ps.v(node) == \"p2\" and F.nu.v(node) == \"sg\") or (suffix == \"K\" or suffix == \"K=\")):\n",
      "                pnMark = '2s'\n",
      "            elif ((F.ps.v(node) == \"p2\" and F.nu.v(node) == \"pl\") or (suffix == \"KM\" or suffix == \"KN\")):\n",
      "                pnMark = '2p'\n",
      "            \n",
      "            if marked_speech and pnMark != \"\":\n",
      "                marked_references[ch][vs][domain + str(volgnr)] += pnMark + \"|\"\n",
      "            elif pnMark != \"\":\n",
      "                unmarked_references[ch][vs][domain + str(volgnr)] += pnMark + \"|\"\n",
      "    \n",
      "    keylist = verses.keys()\n",
      "    keylist = sorted(keylist, key=int)\n",
      "    for p in keylist:\n",
      "        f.write(\"Genesis \" + p + \";Texttype;Unmarked References;Marked References;QuotVerb;Subject;Addressee;;;Text;\\n\")\n",
      "        f.write(\";;;;;;Vocative;Object;Complement;\\n\")\n",
      "       \n",
      "        for v in verses[p]:\n",
      "            f.write(v)\n",
      "            for tt in verse_tts[v]:\n",
      "                f.write(\";\" + tt[:-1] + \";\" + unmarked_references[p][v][tt] + \";\" + marked_references[p][v][tt] + \";\" + verbs[p][v][tt]['vb'] + \";\" + verbs[p][v][tt]['su'] + \";\" + vocatives[p][v][tt] + \";\" + verbs[p][v][tt]['ob'] + \";\" + verbs[p][v][tt]['co'] + \";\" + verbs[p][v][tt]['txt'] + \"\\n\")\n",
      "        f.write(\"\\n\")\n",
      "        \n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analyze_book()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}