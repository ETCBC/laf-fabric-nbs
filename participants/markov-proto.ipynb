{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of all explicit subjects, objects and complements in the Psalms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.6.0\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os, csv, re\n",
    "import collections\n",
    "import subprocess\n",
    "\n",
    "from lxml import etree\n",
    "from pprint import pprint\n",
    "#Visualisation\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "from etcbc.lib import Transcription, monad_set\n",
    "\n",
    "#from etcbc.mql import MQL\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.00s USING annox DATA COMPILED AT: 2016-01-27T19-01-17\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: keep main: F.etcbc4_sft_book [node] \n",
      "  0.01s DETAIL: keep main: F.etcbc4_sft_chapter [node] \n",
      "  0.01s DETAIL: keep main: F.etcbc4_sft_verse [node] \n",
      "  0.01s DETAIL: keep annox: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: keep annox: F.etcbc4_sft_book [node] \n",
      "  0.01s DETAIL: keep annox: F.etcbc4_sft_chapter [node] \n",
      "  0.01s DETAIL: keep annox: F.etcbc4_sft_verse [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_ft_g_word_utf8 [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_ft_lex_utf8 [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_ft_trailer_utf8 [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_kq_g_qere_utf8 [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_kq_qtrailer_utf8 [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_ph_phono [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_ph_phono_sep [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_ft_g_word_utf8 [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_ft_lex_utf8 [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_ft_trailer_utf8 [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_kq_g_qere_utf8 [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_kq_qtrailer_utf8 [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_ph_phono [node] \n",
      "  0.02s DETAIL: clear annox: F.etcbc4_ph_phono_sep [node] \n",
      "  0.02s DETAIL: load main: F.etcbc4_ft_function [node] \n",
      "  0.25s DETAIL: load main: F.etcbc4_ft_g_cons [node] \n",
      "  0.49s DETAIL: load main: F.etcbc4_ft_gn [node] \n",
      "  0.69s DETAIL: load main: F.etcbc4_ft_kind [node] \n",
      "  0.74s DETAIL: load main: F.etcbc4_ft_lex [node] \n",
      "  0.97s DETAIL: load main: F.etcbc4_ft_ls [node] \n",
      "  1.20s DETAIL: load main: F.etcbc4_ft_nu [node] \n",
      "  1.54s DETAIL: load main: F.etcbc4_ft_prs [node] \n",
      "  1.90s DETAIL: load main: F.etcbc4_ft_ps [node] \n",
      "  2.26s DETAIL: load main: F.etcbc4_ft_sp [node] \n",
      "  2.53s DETAIL: load main: F.etcbc4_ft_txt [node] \n",
      "  2.57s DETAIL: load main: F.etcbc4_ft_typ [node] \n",
      "  3.02s DETAIL: load main: F.etcbc4_ft_vs [node] \n",
      "  3.28s DETAIL: load main: F.etcbc4_ft_vt [node] \n",
      "  3.53s DETAIL: load main: F.etcbc4_lex_gloss [node] \n",
      "  3.53s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  3.56s DETAIL: load main: F.etcbc4_ft_functional_parent [e] \n",
      "  3.96s DETAIL: load main: C.etcbc4_ft_functional_parent -> \n",
      "  5.21s DETAIL: load main: C.etcbc4_ft_functional_parent <- \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_function [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_g_cons [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_gn [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_kind [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_lex [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_ls [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_nu [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_prs [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_ps [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_sp [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_txt [node] \n",
      "  5.80s DETAIL: load annox: F.etcbc4_ft_typ [node] \n",
      "  5.81s DETAIL: load annox: F.etcbc4_ft_vs [node] \n",
      "  5.81s DETAIL: load annox: F.etcbc4_ft_vt [node] \n",
      "  5.81s DETAIL: load annox: F.etcbc4_lex_gloss [node] \n",
      "  6.12s DETAIL: load annox: F.etcbc4_sft_label [node] \n",
      "  6.12s DETAIL: load annox: F.etcbc4_ft_functional_parent [e] \n",
      "  6.12s DETAIL: load annox: C.etcbc4_ft_functional_parent -> \n",
      "  6.12s DETAIL: load annox: C.etcbc4_ft_functional_parent <- \n",
      "  6.12s INFO: LOADING PREPARED data: please wait ... \n",
      "  6.12s DETAIL: keep prep: G.node_sort\n",
      "  6.12s DETAIL: keep prep: G.node_sort_inv\n",
      "  6.12s DETAIL: keep prep: L.node_up\n",
      "  6.12s DETAIL: keep prep: L.node_down\n",
      "  6.12s DETAIL: keep prep: V.verses\n",
      "  6.12s DETAIL: keep prep: V.books_la\n",
      "  6.12s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  8.30s INFO: LOADED PREPARED data\n",
      "  8.30s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK mql AT 2016-05-25T13-12-59\n"
     ]
    }
   ],
   "source": [
    "API=fabric.load('etcbc4b', 'lexicon', 'mql', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype nu ps gn vs vt prs ls lex g_cons\n",
    "        function txt\n",
    "        book chapter verse label sp kind typ \n",
    "        gloss\n",
    "    ''',\n",
    "    ''' functional_parent\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))\n",
    "#Q = MQL(API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "divine_lexemes = set('''\n",
    "CDJ/\n",
    ">L/\n",
    ">LH/\n",
    ">LHJM/\n",
    ">LJL/\n",
    ">LWH/'''.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = {}\n",
    "for cn in F.otype.s('clause'):\n",
    "    roles = set()\n",
    "    for pn in L.d('phrase', cn):\n",
    "        role = F.function.v(pn)\n",
    "        if role in {'Subj', 'Objc', 'Cmpl'}:\n",
    "            if {w for w in L.d('word', pn) if F.lex.v(w) in divine_lexemes}:\n",
    "                roles.add(role)\n",
    "    if 'Subj' in roles: states[cn] = 3\n",
    "    elif 'Objc' in roles: states[cn] = 2\n",
    "    elif 'Cmpl' in roles: states[cn] = 1\n",
    "    else: states[cn] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexemes denoting God:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'>L/', '>LH/', '>LHJM/', '>LJL/', '>LWH/'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{F.lex.v(w) for w in F.otype.s('word') if F.gloss.v(w).startswith('god')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88011"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 85811, 1: 658, 2: 441, 3: 1101})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = collections.defaultdict(lambda: collections.Counter())\n",
    "for (cn, state) in states.items(): stats['state'][state] += 1\n",
    "stats['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_list = [states[cn] for cn in F.otype.s('clause')]\n",
    "transitions = [(states_list[i], states_list[i+1]) for i in range(len(states_list)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0),\n",
       " (0, 0),\n",
       " (0, 3),\n",
       " (3, 3),\n",
       " (3, 0),\n",
       " (0, 0),\n",
       " (0, 3),\n",
       " (3, 0),\n",
       " (0, 3),\n",
       " (3, 3)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(0, 0): 83765,\n",
       "         (0, 1): 601,\n",
       "         (0, 2): 416,\n",
       "         (0, 3): 1028,\n",
       "         (1, 0): 594,\n",
       "         (1, 1): 32,\n",
       "         (1, 2): 10,\n",
       "         (1, 3): 22,\n",
       "         (2, 0): 413,\n",
       "         (2, 1): 13,\n",
       "         (2, 2): 8,\n",
       "         (2, 3): 7,\n",
       "         (3, 0): 1039,\n",
       "         (3, 1): 12,\n",
       "         (3, 2): 7,\n",
       "         (3, 3): 43})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in transitions: stats['trans'][x] += 1\n",
    "stats['trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_words(phrase):\n",
    "    '''Takes as argument a phrase-node and turns it into transliterated words.\n",
    "    Function is called in def get_soc_info().'''\n",
    "    words_str = ''\n",
    "    words = L.d('word', phrase)\n",
    "    for word in words:\n",
    "        words_str += F.g_cons.v(word)\n",
    "        if not word == words[-1]:\n",
    "            words_str += '_'\n",
    "    return words_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_soc_info():\n",
    "    '''Function iterates over all clauses in the Psalms and searches for phrases within those clauses with an\n",
    "    explicit subject, object or complement (soc). In the phrases_in_clause_dict nodes are added to the soc info\n",
    "    for ease of reference.'''\n",
    "    clause_lst = []\n",
    "    phrases_in_clause_dict = collections.defaultdict(list)\n",
    "    for node in NN():\n",
    "        clause_info = []\n",
    "        if F.otype.v(node) == 'clause': \n",
    "            if F.book.v(L.u('book', node)) == 'Psalmi':\n",
    "                clause_lst.append(node)\n",
    "                clause_info.append(str(node))\n",
    "                clause_info.append(str(F.chapter.v(L.u('chapter', node))))\n",
    "                clause_info.append(str(F.verse.v(L.u('verse', node))))\n",
    "                phrases = L.d('phrase', node)\n",
    "                phrase_identifier = collections.defaultdict(list)\n",
    "                for phrase in phrases:\n",
    "                    if F.function.v(phrase) in ['Subj', 'Objc', 'Cmpl']:\n",
    "                        phrase_identifier[F.function.v(phrase)].append(phrase)\n",
    "                        #print(phrase_identifier)\n",
    "\n",
    "                #check for empty entries     \n",
    "                if len(phrase_identifier) > 0:\n",
    "                    if 'Subj' in phrase_identifier:\n",
    "                        clause_info.append(phrase_identifier['Subj'][0])   \n",
    "                        clause_info.append(make_words(phrase_identifier['Subj'][0]))\n",
    "                    else: \n",
    "                        clause_info.append('_')\n",
    "                        clause_info.append('_')\n",
    "                    for fc in ['Objc', 'Cmpl']:\n",
    "                        if fc in phrase_identifier:\n",
    "                            length = len(phrase_identifier[fc])\n",
    "                            if length == 1:\n",
    "                                clause_info.append(phrase_identifier[fc][0])\n",
    "                                clause_info.append(make_words(phrase_identifier[fc][0]))\n",
    "                                clause_info.append('_')\n",
    "                                clause_info.append('_')\n",
    "                            elif length == 2:\n",
    "                                clause_info.append(phrase_identifier[fc][0])\n",
    "                                clause_info.append(make_words(phrase_identifier[fc][0]))\n",
    "                                clause_info.append(phrase_identifier[fc][1])\n",
    "                                clause_info.append(make_words(phrase_identifier[fc][1]))\n",
    "                        else:\n",
    "                            for item in range(4):\n",
    "                                clause_info.append('_')\n",
    "                    phrases_in_clause_dict[node] = clause_info\n",
    "                    #print(clause_info)\n",
    "\n",
    "    return clause_lst, phrases_in_clause_dict      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clause_lst, phrases_in_clause_dict = get_soc_info()\n",
    "\n",
    "with open(\"explicit-subjects-objects-complements.csv\", 'w') as f:\n",
    "    header = ['clnode', 'chapter', 'verse', 'subj_n', 'subj', 'obj_n', 'obj', 'obj_n2', 'obj2', \n",
    "              'cmpl_n', 'cmpl', 'cmpl_n2', 'cmpl2']\n",
    "    f.write('{}\\n'.format(','.join(header)))\n",
    "\n",
    "    for clause in clause_lst:\n",
    "        if len(phrases_in_clause_dict[clause]) > 0:\n",
    "            line = []\n",
    "            for element in phrases_in_clause_dict[clause]:\n",
    "                line.append(str(element))\n",
    "            f.write('{}\\n'.format(','.join(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
