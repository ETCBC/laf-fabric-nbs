{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-small.png\"/></a>\n",
    "<a href=\"https://shebanq.ancient-data.org\" target=\"_blank\"><img align=\"left\"src=\"images/shebanq_logo_small.png\"/></a>\n",
    "<a href=\"http://dx.doi.org/10.17026/dans-z6y-skyh\" target=\"_blank\"><img align=\"left\"src=\"images/DANS-logo_small.png\"/></a>\n",
    "<a href=\"https://www.dbg.de/index.php?L=1\" target=\"_blank\"><img align=\"right\" src=\"images/DBG-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-small.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 2016-03-14\n",
    "\n",
    "# 1. Datamodel: \n",
    "\n",
    "## 1.1 ETCBC data in the Emdros model\n",
    "\n",
    "See the [otype](https://shebanq.ancient-data.org/shebanq/static/docs/featuredoc/features/comments/otype.html) feature.\n",
    "\n",
    "And then the [overview](https://shebanq.ancient-data.org/shebanq/static/docs/featuredoc/features/comments/0_overview.html) of features.\n",
    "\n",
    "[SHEBANQ](https://shebanq.ancient-data.org) is your friend, especially the **Help** there.\n",
    "\n",
    "## 1.2 Let's go LAF\n",
    "\n",
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/LAF.pdf\"/></a>\n",
    "\n",
    "## 1.3 Let's forget LAF\n",
    "\n",
    "**LAF-Fabric**\n",
    "* has read all the LAF-XML\n",
    "* has built a datastructure (graph)\n",
    "* has saved the data structure on disk\n",
    "* will load the relevant parts for you quickly\n",
    "\n",
    "# 2. API\n",
    "\n",
    "We'll start the API, but first we have to import the necessary modules.\n",
    "``sys, collections, re`` are not necessary for LAF-Fabric, but may come in handy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.21\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, collections, re\n",
    "\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LafFabric` is a class offered by the `laf.fabric` module, and have created just one object of that class, and stored it in the variable `fabric`.\n",
    "\n",
    "Note the links to the documentation.\n",
    "\n",
    "LAF-Fabric can work with several data sources and versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source='etcbc'\n",
    "version='4b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Loading data\n",
    "\n",
    "The `load` method is a function that listens to your data requirements, and manages to keep in memory exactly what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s USING annox DATA COMPILED AT: 2016-01-27T19-01-17\n",
      "  2.49s LOGFILE=/Users/dirk/laf-fabric-output/etcbc4b/workshop/__log__workshop.txt\n",
      "  2.49s INFO: LOADING PREPARED data: please wait ... \n",
      "  2.49s prep prep: G.node_sort\n",
      "  2.60s prep prep: G.node_sort_inv\n",
      "  3.12s prep prep: L.node_up\n",
      "  6.63s prep prep: L.node_down\n",
      "    12s prep prep: V.verses\n",
      "    12s prep prep: V.books_la\n",
      "    12s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    14s INFO: LOADED PREPARED data\n",
      "    14s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK workshop AT 2016-03-14T13-12-54\n"
     ]
    }
   ],
   "source": [
    "API=fabric.load(source+version, 'lexicon', 'workshop', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype\n",
    "        lex\n",
    "        sp gloss\n",
    "        chapter verse\n",
    "    ''',''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "})\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2 ETCBC additions\n",
    "\n",
    "The `laf` modules know nothing about Hebrew data, nor about ETCBC data features.\n",
    "\n",
    "The `etcbc` modules bring in specific knowledge about how the ETCBC data has been modeled in LAF. It knows\n",
    "* it knows that *sentences* contain *clauses* contain *phrases*\n",
    "* it can order all nodes in a logical order\n",
    "* it can find parts and wholes\n",
    "* it can print text content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tasks\n",
    "\n",
    "## 3.1 Exploration\n",
    "\n",
    "### 3.1.1 Show the first 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367497 book\n",
      "1367536 chapter\n",
      "1413645 verse\n",
      "1125793 sentence\n",
      "1189379 sentence_atom\n",
      "426568 clause\n",
      "514579 clause_atom\n",
      "1368465 half_verse\n",
      "605133 phrase\n",
      "858294 phrase_atom\n",
      "0 word\n",
      "1 word\n",
      "605134 phrase\n",
      "858295 phrase_atom\n",
      "2 word\n",
      "605135 phrase\n",
      "858296 phrase_atom\n",
      "3 word\n",
      "1368466 half_verse\n",
      "605136 phrase\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for n in NN():\n",
    "    print('{} {}'.format(n, F.otype.v(n)))\n",
    "    i += 1\n",
    "    if i >= 20: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Count all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 9m 11s Counting\n",
      " 9m 12s Done. 1436858 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436858\n"
     ]
    }
   ],
   "source": [
    "msg('Counting')\n",
    "\n",
    "i = 0\n",
    "for n in NN(): i += 1\n",
    "print(i)\n",
    "\n",
    "msg('Done. {} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Count the nodes per object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12m 54s Counting per object type\n",
      "12m 56s Done. 12 distinct object types\n"
     ]
    }
   ],
   "source": [
    "msg('Counting per object type')\n",
    "\n",
    "counts = collections.Counter()\n",
    "for n in NN(): counts[F.otype.v(n)] += 1\n",
    "\n",
    "msg('Done. {} distinct object types'.format(len(counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how many nodes per object type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter has 929 nodes\n",
      "subphrase has 113764 nodes\n",
      "sentence has 63586 nodes\n",
      "sentence_atom has 64354 nodes\n",
      "word has 426568 nodes\n",
      "half_verse has 45180 nodes\n",
      "clause_atom has 90554 nodes\n",
      "verse has 23213 nodes\n",
      "phrase_atom has 267499 nodes\n",
      "clause has 88011 nodes\n",
      "book has 39 nodes\n",
      "phrase has 253161 nodes\n"
     ]
    }
   ],
   "source": [
    "for tp in counts: print('{} has {} nodes'.format(tp, counts[tp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now more pretty, sorted by most numerous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                :  426568 nodes\n",
      "phrase_atom         :  267499 nodes\n",
      "phrase              :  253161 nodes\n",
      "subphrase           :  113764 nodes\n",
      "clause_atom         :   90554 nodes\n",
      "clause              :   88011 nodes\n",
      "sentence_atom       :   64354 nodes\n",
      "sentence            :   63586 nodes\n",
      "half_verse          :   45180 nodes\n",
      "verse               :   23213 nodes\n",
      "chapter             :     929 nodes\n",
      "book                :      39 nodes\n"
     ]
    }
   ],
   "source": [
    "for (tp, n) in sorted(counts.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print('{:<20}: {:>7} nodes'.format(tp, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Find a passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413645\n"
     ]
    }
   ],
   "source": [
    "# for convenience, we use swahili bible book names\n",
    "my_node = T.node_of(T.book_node('Mwanzo', lang='sw'), 1, 1)\n",
    "\n",
    "print(my_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the word nodes of that passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "my_words = L.d('word', my_node)\n",
    "print(my_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(T.words(my_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can get it in other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בראשית ברא אלהימ את השמימ ואת הארצ׃\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(T.words(my_words, fmt='hc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get it in all available formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hp',\n",
       "              ('hebrew primary',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('ha',\n",
       "              ('hebrew accent',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('hv',\n",
       "              ('hebrew vowel',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('hc',\n",
       "              ('hebrew cons',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('ea',\n",
       "              ('trans accent',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('ev',\n",
       "              ('trans vowel',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('ec',\n",
       "              ('trans cons',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('pf',\n",
       "              ('phono full',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>)),\n",
       "             ('ps',\n",
       "              ('phono simple',\n",
       "               <function etcbc.text.Text.__init__.<locals>.<lambda>>))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n",
      "\n",
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n",
      "\n",
      "בְּרֵאשִׁית בָּרָא אֱלֹהִים אֵת הַשָּׁמַיִם וְאֵת הָאָרֶץ׃\n",
      "\n",
      "בראשית ברא אלהימ את השמימ ואת הארצ׃\n",
      "\n",
      "B.:R;>CI73JT B.@R@74> >:ELOHI92Jm >;71T HAC.@MA73JIm W:>;71T H@>@95REy00\n",
      "\n",
      "B.:R;>CIJT B.@R@> >:ELOHIJm >;T HAC.@MAJIm W:>;T H@>@REy00\n",
      "\n",
      "BR>#JT BR> >LHJM >T H#MJM W>T H>RY00\n",
      "\n",
      "bᵊrēšˌîṯ bārˈā ʔᵉlōhˈîm ʔˌēṯ haššāmˌayim wᵊʔˌēṯ hāʔˈāreṣ .\n",
      "\n",
      "brēšîṯ bårå ʔlōhîm ʔēṯ haššåmayim wʔēṯ håʔåreṣ .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in T.formats(): print('{}'.format(T.words(my_words, fmt=f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With a bit more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp=hebrew primary בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n",
      "\n",
      "ha=hebrew accent בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n",
      "\n",
      "hv=hebrew vowel בְּרֵאשִׁית בָּרָא אֱלֹהִים אֵת הַשָּׁמַיִם וְאֵת הָאָרֶץ׃\n",
      "\n",
      "hc=hebrew cons בראשית ברא אלהימ את השמימ ואת הארצ׃\n",
      "\n",
      "ea=trans accent B.:R;>CI73JT B.@R@74> >:ELOHI92Jm >;71T HAC.@MA73JIm W:>;71T H@>@95REy00\n",
      "\n",
      "ev=trans vowel B.:R;>CIJT B.@R@> >:ELOHIJm >;T HAC.@MAJIm W:>;T H@>@REy00\n",
      "\n",
      "ec=trans cons BR>#JT BR> >LHJM >T H#MJM W>T H>RY00\n",
      "\n",
      "pf=phono full bᵊrēšˌîṯ bārˈā ʔᵉlōhˈîm ʔˌēṯ haššāmˌayim wᵊʔˌēṯ hāʔˈāreṣ .\n",
      "\n",
      "ps=phono simple brēšîṯ bårå ʔlōhîm ʔēṯ haššåmayim wʔēṯ håʔåreṣ .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (f, (desc, method)) in T.formats().items(): print('{}={} {}'.format(f, desc, T.words(my_words, fmt=f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Advanced tasks\n",
    "\n",
    "## 4.1 Adding annotations.\n",
    "\n",
    "See notebook valence/flow_corr.\n",
    "\n",
    "## 4.2 R\n",
    "\n",
    "See notebooks shebanq/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
