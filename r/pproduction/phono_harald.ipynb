{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
    "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phonological representation\n",
    "\n",
    "Here comes the plain text of the Hebrew Bible in a phonological/phonetic representation augmented with lexical and morphological features in a handy representation to do trigram analysis on the Hebrew text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "[phono.csv](phono.csv), a tab delimited file (ca 15 MB) with the following fields:\n",
    "\n",
    "    book chapter verse wordentry\n",
    "\n",
    "``wordentry`` is a composite field. It is an underscore separated list of the following fields\n",
    "\n",
    "    phonetic                   phonetic representation of word occurrence\n",
    "    lexeme                     lexeme identifier\n",
    "    verb.stem                  all values on verbs are prefixed with v.\n",
    "    verb.tense\n",
    "    verb.person\n",
    "    verb.number\n",
    "    verb.gender\n",
    "    noun.number                all values on nouns are prefixed with n.\n",
    "    noun.gender\n",
    "    noun.state\n",
    "    adjv.number                all values on adjectives are prefixed with a.\n",
    "    adjv.gender\n",
    "    h-ending                   heh locale\n",
    "    nounsuff.person            pronominal suffix on noun, all values prefixed with ns.\n",
    "    nounsuff.number\n",
    "    nounsuff.gender\n",
    "    verbsuff.person            pronominal suffix on verb, all values prefixed with vs.\n",
    "    verbsuff.number\n",
    "    verbsuff.gender\n",
    "\n",
    "The words are taken together if written together, but a maqef (-) is taken as a word separator.\n",
    "Each of these superwords contains at most inflectional word.\n",
    "The attributes that are given for a superword are the attributes that belong to its inflectional nucleus.\n",
    "\n",
    "## Phonetic transcription\n",
    "\n",
    "The phonetic description is documented in the [phono notebook](https://shebanq.ancient-data.org/shebanq/static/docs/tools/phono/phono.html) on SHEBANQ.\n",
    "\n",
    "But for the purposes here the following simplifications are applied:\n",
    "\n",
    "* we remove all schwas\n",
    "* we identify qamets gadol and qatan\n",
    "* we remove the accent marks\n",
    "* we use the qere and ignore the ketiv where they are different\n",
    "* the `[ ]` around the tetragrammaton are removed (the occurrences can still be recognized by lexeme=`JHWH/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.12\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os, collections, re\n",
    "\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "from etcbc.lib import Transcription\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s USING annox DATA COMPILED AT: 2016-01-27T19-01-17\n",
      "  8.82s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/pproduction/__log__pproduction.txt\n",
      "  8.82s INFO: LOADING PREPARED data: please wait ... \n",
      "  8.82s prep prep: G.node_sort\n",
      "  8.95s prep prep: G.node_sort_inv\n",
      "  9.61s prep prep: L.node_up\n",
      "    14s prep prep: L.node_down\n",
      "    21s prep prep: V.verses\n",
      "    21s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    23s INFO: LOADED PREPARED data\n",
      "    23s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK pproduction AT 2016-02-23T09-22-39\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "fabric.load('etcbc{}'.format(version), 'lexicon', 'pproduction', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype monads\n",
    "        phono phono_sep\n",
    "        lex\n",
    "        sp vs vt gn nu ps st\n",
    "        uvf prs pfm vbs vbe\n",
    "        language\n",
    "        book chapter verse label\n",
    "    ''',''),\n",
    "    \"prepare\": prepare,\n",
    "})\n",
    "exec(fabric.localnames.format(var='fabric'))\n",
    "trans = Transcription()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Compile \"phonetic\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prs_map = {\n",
    "    'W':  '3sm',\n",
    "    'K':  '2sm',\n",
    "    'J':  '1sc',\n",
    "    'M':  '3pm',\n",
    "    'H':  '3sf',\n",
    "    'HM': '3pm',\n",
    "    'KM': '2pm',\n",
    "    'NW': '1pc',\n",
    "    'HW': '3sm',\n",
    "    'NJ': '1sc',\n",
    "    'K=': '2sf',\n",
    "    'HN': '3pf',\n",
    "    'MW': '3pm',\n",
    "    'N':  '3pf',\n",
    "    'KN': '2pf',\n",
    "}\n",
    "\n",
    "def expand(mrf, pref): return '_'.join(pref+'.'+x for x in mrf)\n",
    "\n",
    "fmt_str = '{}\\t'+('_'.join(['{}'] * 11)) + '\\n'\n",
    "\n",
    "png = dict(\n",
    "    NA='',\n",
    "    unknown='',\n",
    "    p1='1',\n",
    "    p2='2',\n",
    "    p3='3',\n",
    "    sg='s',\n",
    "    du='d',\n",
    "    pl='p',\n",
    "    m='m',\n",
    "    f='f',\n",
    "    a='a',\n",
    "    c='c',\n",
    "    e='e',\n",
    ")\n",
    "undefs = {'NA', 'unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phonetics\n",
    "\n",
    "We use the phonetic representation, stored in the features `phono` and `phono_sep`.\n",
    "\n",
    "Interword material is in `phono_sep`, which can have only three values: empty string, space, or space followed by ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = 2 = 3\n"
     ]
    }
   ],
   "source": [
    "x = '1'\n",
    "i = 1\n",
    "(pre, this, post) = (x+'23')[i-1:i+2]\n",
    "print('{} = {} = {}'.format(pre, this, post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1h 35m 24s Yods\n",
      " 1h 35m 25s Done {} small yods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rest: 32x\n",
      "e: 905x\n",
      "w: 935x\n"
     ]
    }
   ],
   "source": [
    "msg('Yods')\n",
    "yod = set()\n",
    "small_yods = collections.defaultdict(set)\n",
    "for w in F.otype.s('word'):\n",
    "    ph = F.phono.v(w)\n",
    "    i = ph.find('ʸ')\n",
    "    if i != -1:\n",
    "        (pre, yod, post) = (ph+'xx')[i-1:i+2]\n",
    "        if pre == 'e': small_yods['e'].add(ph)\n",
    "        elif post == 'w': small_yods['w'].add(ph)\n",
    "        else: small_yods['rest'].add(ph)\n",
    "msg('Done {} small yods')\n",
    "for (x,y) in small_yods.items():\n",
    "    print('{}: {}x'.format(x, len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heḥᵉʸiṯˈānû\n",
      "heḥᵉʸˈêṯî\n",
      "heḥᵉʸˈā\n",
      "heḥᵉʸˌā\n",
      "hˈᵉʸôṯ-\n",
      "hˈᵉʸē-\n",
      "hᵉʸiṯˌem\n",
      "hᵉʸîṯˈem\n",
      "hᵉʸîṯˌem\n",
      "hᵉʸôṯ\n",
      "hᵉʸôṯ-\n",
      "hᵉʸôṯˈô\n",
      "hᵉʸôṯˈām\n",
      "hᵉʸôṯˈēḵ\n",
      "hᵉʸôṯˌî\n",
      "hᵉʸôṯˌāh\n",
      "hᵉʸôṯˌām\n",
      "hᵉʸôṯˌēnû\n",
      "hᵉʸôṯᵊḵˈā\n",
      "hᵉʸē-\n",
      "hᵉʸˈîṯem\n",
      "hᵉʸˈôṯ\n",
      "hᵉʸˈôṯ-\n",
      "hᵉʸˈôṯᵊḵem\n",
      "hᵉʸˈē\n",
      "hᵉʸˌôṯ\n",
      "hᵉʸˌû\n",
      "lˈeḥᵉʸô\n",
      "lˈeḥᵉʸˈāh\n",
      "ʔᵉʸˈāl\n",
      "ˈʔᵉʸālûṯˈî\n",
      "ḥᵉʸˈî\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(small_yods['rest']):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50m 48s Furtive\n",
      "50m 49s Done 10 furtives, 13 strange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ē', 'i', 'ō', 'ô', 'ê', 'a', 'ˌ', 'u', 'î', 'û'}\n",
      "{'mmiqṣôˌₐʕ', 'yārôˌₐḥ', 'hišmîˌₐʕ', 'maddûˌₐʕ', 'haddîˌₐḥ', 'rûˌₐḥ', 'hiznîˌₐḥ', 'ššᵊmôˌₐʕ', 'yānôˌₐḥ', 'hinnîˌₐḥ', 'zānôˌₐḥ', 'rāqîˌₐʕ', 'ʔᵉlôˌₐh'}\n"
     ]
    }
   ],
   "source": [
    "msg('Furtive')\n",
    "furtives = set()\n",
    "strange_furtives = set()\n",
    "for w in F.otype.s('word'):\n",
    "    ph = F.phono.v(w)\n",
    "    i = ph.find('ₐ')\n",
    "    if i != -1:\n",
    "        furtives.add(ph[i-1])\n",
    "        if ph[i-1] == 'ˌ': strange_furtives.add(ph)\n",
    "msg('Done {} furtives, {} strange'.format(len(furtives), len(strange_furtives)))\n",
    "print(furtives)\n",
    "print(strange_furtives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ē, I, Ō, Ô, Ê, A, ˌ, U, Î, Û\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(x.upper() for x in furtives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ˌₐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2.64s Tetra\n",
      "  4.60s Done. 31 tetras\n"
     ]
    }
   ],
   "source": [
    "msg('Tetra')\n",
    "tetras = set()\n",
    "for w in F.otype.s('word'):\n",
    "    ph = F.phono.v(w)\n",
    "    if F.lex.v(w) == 'JHWH/': tetras.add(ph)\n",
    "msg('Done. {} tetras'.format(len(tetras)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[yhwāh]\n",
      "[yhwˈāh]\n",
      "[yhwˌih]\n",
      "[yhwˌāh]\n",
      "[yhôˈāh]\n",
      "[yhôˌāh]\n",
      "[yᵃhwˌāh]\n",
      "[yᵉhwˈih]\n",
      "[yᵉhwˌih]\n",
      "[yᵉhôˈih]\n",
      "[yᵊhwih]\n",
      "[yᵊhwāh]\n",
      "[yᵊhwˈih]\n",
      "[yᵊhwˈāh]\n",
      "[yᵊhwˈˌāh]-\n",
      "[yᵊhwˌih]\n",
      "[yᵊhwˌāh]\n",
      "[yᵊhôˈih]\n",
      "[yᵊhôˈāh]\n",
      "[yᵊhôˌih]\n",
      "[yᵊhôˌāh]\n",
      "[yᵊhˈwāh]\n",
      "[yᵊhˈwˈih]\n",
      "[yᵊhˈwˈāh]\n",
      "[yᵊhˈwˌāh]\n",
      "[yᵊˈhwˈāh]\n",
      "[ˈyhwāh]\n",
      "[ˈyhwˈih]\n",
      "[ˈyhwˈāh]\n",
      "[ˈyhôāh]\n",
      "[ˈyhôˈāh]\n"
     ]
    }
   ],
   "source": [
    "for t in sorted(tetras):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tetra_map = {\n",
    "    '[yhwāh]': 'ʔᵃḏōnåy',\n",
    "    '[yhwˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[yhwˌih]': 'ʔᵉlōhîm',\n",
    "    '[yhwˌāh]': 'ʔᵃḏōnåy',\n",
    "    '[yhôˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[yhôˌāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵃhwˌāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵉhwˈih]': 'ʔᵉlōhîm',\n",
    "    '[yᵉhwˌih]': 'ʔᵉlōhîm',\n",
    "    '[yᵉhôˈih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhwih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhwāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhwˈih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhwˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhwˈˌāh]': 'ʔᵃḏōnåy', # xxxx\n",
    "    '[yᵊhwˌih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhwˌāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhôˈih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhôˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhôˌih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhôˌāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhˈwāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhˈwˈih]': 'ʔᵉlōhîm',\n",
    "    '[yᵊhˈwˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊhˈwˌāh]': 'ʔᵃḏōnåy',\n",
    "    '[yᵊˈhwˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[ˈyhwāh]': 'ʔᵃḏōnåy',\n",
    "    '[ˈyhwˈih]': 'ʔᵉlōhîm',\n",
    "    '[ˈyhwˈāh]': 'ʔᵃḏōnåy',\n",
    "    '[ˈyhôāh]': 'ʔᵃḏōnåy',\n",
    "    '[ˈyhôˈāh]': 'ʔᵃḏōnåy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tetra_pat = re.compile('(\\[[^]]*\\])')\n",
    "furtive_pat = re.compile('(.)ₐ')\n",
    "\n",
    "def tetra_repl(match):\n",
    "    return tetra_map[match.group(1)]\n",
    "\n",
    "def furtive_repl(match):\n",
    "    return match.group(1).upper()\n",
    "\n",
    "def phono_old(w): return F.phono.v(w).\\\n",
    "    replace('ᵊ', '').\\\n",
    "    replace('ā', 'å').\\\n",
    "    replace('o', 'å').\\\n",
    "    replace('ˈ', '').\\\n",
    "    replace('ˌ', '').\\\n",
    "    replace('*', '').\\\n",
    "    replace('[', '').\\\n",
    "    replace(']', '')\n",
    "    \n",
    "def phono(w):\n",
    "    ph = tetra_pat.sub(tetra_repl, F.phono.v(w))\n",
    "    ph =  ph.\\\n",
    "    replace('ᵊ', '').\\\n",
    "    replace('ᵉ', '').\\\n",
    "    replace('ᵃ', '').\\\n",
    "    replace('ᵒ', '').\\\n",
    "    replace('ā', 'å').\\\n",
    "    replace('o', 'å').\\\n",
    "    replace('ˈ', '').\\\n",
    "    replace('ˌ', '').\\\n",
    "    replace('*', '').\\\n",
    "    replace(' ', '').\\\n",
    "    replace('-', '').\\\n",
    "    replace('eʸ', 'e').\\\n",
    "    replace('ʸw', 'w').\\\n",
    "    replace('ʸ', 'y')\n",
    "    ph = furtive_pat.sub(furtive_repl, ph)\n",
    "    return ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxEzzUyy\n"
     ]
    }
   ],
   "source": [
    "vb = 'xxeₐzzuₐyy'\n",
    "print(furtive_pat.sub(furtive_repl, vb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'': 164105, ' ': 239251, ' .': 23212})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as a check: collect all seps\n",
    "seps = collections.Counter()\n",
    "for w in F.otype.s('word'):\n",
    "    seps[F.phono_sep.v(w)] += 1\n",
    "seps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No _ in feature values\n"
     ]
    }
   ],
   "source": [
    "# just as check: is there an underscore in the uvf pfm vbs vbe  features?\n",
    "vals = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
    "features = ['uvf', 'pfm', 'vbs', 'vbe']\n",
    "for w in F.otype.s('word'):\n",
    "    for f in features:\n",
    "        val = F.item[f].v(w)\n",
    "        if '_' in val:\n",
    "            vals[f][val].append(w)\n",
    "print(vals if vals else 'No _ in feature values')\n",
    "# the answer should be no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_passage(w):\n",
    "    vn = w if F.otype.v(w) == 'verse' else L.u('verse', w)\n",
    "    return '{}\\t{}\\t{}'.format(\n",
    "        F.book.v(L.u('book', w)),\n",
    "        F.chapter.v(L.u('chapter', w)),\n",
    "        F.verse.v(vn),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting exception\n",
    "\n",
    "The basic units are words as they are written together.\n",
    "The maqef separates words.\n",
    "Then every unit has at most one word in the class noun-verb-adjective.\n",
    "\n",
    "However, there is one exception, in Jesaia 9:5: ʔᵃvîʕˌaḏ (אֲבִיעַ֖ד) is written together, but analysed as two words.\n",
    "So we use a list of words that we want to add a separating space to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitx = {'215237'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1h 38m 26s Generating phonetic data file ...\n",
      " 1h 38m 27s 1000  verses with 0 split errors\n",
      " 1h 38m 27s 2000  verses with 0 split errors\n",
      " 1h 38m 28s 3000  verses with 0 split errors\n",
      " 1h 38m 29s 4000  verses with 0 split errors\n",
      " 1h 38m 29s 5000  verses with 0 split errors\n",
      " 1h 38m 30s 6000  verses with 0 split errors\n",
      " 1h 38m 31s 7000  verses with 0 split errors\n",
      " 1h 38m 32s 8000  verses with 0 split errors\n",
      " 1h 38m 33s 9000  verses with 0 split errors\n",
      " 1h 38m 33s 10000 verses with 0 split errors\n",
      " 1h 38m 34s 11000 verses with 0 split errors\n",
      " 1h 38m 34s 12000 verses with 0 split errors\n",
      " 1h 38m 35s 13000 verses with 0 split errors\n",
      " 1h 38m 36s 14000 verses with 0 split errors\n",
      " 1h 38m 36s 15000 verses with 0 split errors\n",
      " 1h 38m 37s 16000 verses with 0 split errors\n",
      " 1h 38m 37s 17000 verses with 0 split errors\n",
      " 1h 38m 37s 18000 verses with 0 split errors\n",
      " 1h 38m 38s 19000 verses with 0 split errors\n",
      " 1h 38m 38s 20000 verses with 0 split errors\n",
      " 1h 38m 39s 21000 verses with 0 split errors\n",
      " 1h 38m 39s 22000 verses with 0 split errors\n",
      " 1h 38m 40s 23000 verses with 0 split errors\n",
      " 1h 38m 40s 23213 verses with 0 split errors. Done\n"
     ]
    }
   ],
   "source": [
    "msg('Generating phonetic data file ...')\n",
    "\n",
    "phono_file = open(\"phono.csv\", 'w')\n",
    "\n",
    "headline = fmt_str.format(\n",
    "    'book\\tchapter\\tverse', \n",
    "    'phonetic',\n",
    "    'lexeme',\n",
    "    'verb.stem',\n",
    "    'verb.tense',\n",
    "    'verb.person_verb.number_verb.gender',\n",
    "    'noun.number_noun.gender',\n",
    "    'noun.state',\n",
    "    'adjv.number_adjv.gender',\n",
    "    'h-ending',\n",
    "    'nounsuff.person_nounsuff.number_nounsuff.gender',\n",
    "    'verbsuff.person_verbsuff.number_verbsuff.gender',\n",
    ")\n",
    "phono_file.write(headline)\n",
    "\n",
    "chunksize = 1000\n",
    "nv = 0\n",
    "nc = 0\n",
    "spliterrors = 0\n",
    "\n",
    "for v in F.otype.s('verse'):\n",
    "    nv += 1\n",
    "    nc += 1\n",
    "    if nc == chunksize:\n",
    "        nc = 0\n",
    "        msg('{:<5} verses with {} split errors'.format(nv, spliterrors))\n",
    "    passage_label = get_passage(v)\n",
    "    lines = []\n",
    "    words = L.d('word', v)\n",
    "    cur_line = []\n",
    "    cur_sep = ''\n",
    "    skip = False\n",
    "    for w in words:\n",
    "        if F.language.v(w) == 'Aramaic':\n",
    "            skip = True\n",
    "            break\n",
    "        the_monad = F.monads.v(w)\n",
    "        if the_monad in splitx: the_sep = ' '\n",
    "        else: the_sep = (' ' if F.phono.v(w).endswith('-') else '') + F.phono_sep.v(w)\n",
    "        if cur_sep == '':\n",
    "            cur_line.append(w)\n",
    "        else:\n",
    "            if cur_line:\n",
    "                lines.append(cur_line)\n",
    "            cur_line = [w]\n",
    "        cur_sep = the_sep\n",
    "    if skip: continue\n",
    "    if cur_line: lines.append(cur_line)\n",
    "    \n",
    "    for line in lines:\n",
    "        line_text = ''\n",
    "        for w in line: line_text += phono(w)\n",
    "        lex_ident = '~'.join(F.lex.v(w).replace('_', '#') for w in line)\n",
    "        verb_stem = '%'.join('v.{}'.format(F.vs.v(w)) for w in line if F.sp.v(w) == 'verb')\n",
    "        verb_tense = '%'.join('v.{}'.format(F.vt.v(w)) for w in line if F.sp.v(w) == 'verb')\n",
    "        png_verb = '%'.join('v.{}_v.{}_v.{}'.format(\n",
    "            png[F.ps.v(w)], png[F.nu.v(w)], png[F.gn.v(w)],\n",
    "        ) for w in line if F.sp.v(w) == 'verb')\n",
    "        png_noun = '%'.join('n.{}_n.{}'.format(\n",
    "            png[F.nu.v(w)], png[F.gn.v(w)],\n",
    "        ) for w in line if F.sp.v(w) == 'subs')\n",
    "        png_adjv = '%'.join('a.{}_a.{}'.format(\n",
    "            png[F.nu.v(w)], png[F.gn.v(w)],\n",
    "        ) for w in line if F.sp.v(w) == 'adjv')\n",
    "        nom_st = '%'.join('n.{}'.format(png[F.st.v(w)]) for w in line if F.sp.v(w) == 'subs')\n",
    "        uvf_h = '%'.join('h' for w in line if F.uvf.v(w) == 'H')\n",
    "        prs_noun = '%'.join(expand(prs_map.get(F.prs.v(w), ''), 'ns') for w in line if F.sp.v(w) == 'subs')\n",
    "        prs_verb = '%'.join(expand(prs_map.get(F.prs.v(w), ''), 'vs') for w in line if F.sp.v(w) == 'verb')\n",
    "\n",
    "        line = fmt_str.format(\n",
    "            passage_label, \n",
    "            line_text,\n",
    "            lex_ident,\n",
    "            verb_stem,\n",
    "            verb_tense,\n",
    "            png_verb,\n",
    "            png_noun,\n",
    "            nom_st,\n",
    "            png_adjv,\n",
    "            uvf_h,\n",
    "            prs_noun,\n",
    "            prs_verb,\n",
    "        )\n",
    "        if '%' in line:\n",
    "            spliterrors += 1\n",
    "        phono_file.write(line)\n",
    "phono_file.close()\n",
    "msg('{:<5} verses with {} split errors. Done'.format(nv, spliterrors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
